---
title: "Sampling algorithms"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Sampling algorithms}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "./Sampling-algorithms-",
  tidy.opts = list(width.cutoff = 60),
  tidy = TRUE
)
```

```{r load packages, message = FALSE}
sapply(c("modulr", "ggplot2", "ggthemes", "igraph"), require, character = TRUE)
```

We'll build on code and network we simulated in the readme. Again, we specify parameters:

```{r params}
ng = 5 # number of groups in the network
na = 30 # number of animals in the network
tl = 7 # average number of days spent at a home patch before leaving
tr = 2 # average number of days spent at a non-resident patch before returning home
tt = c(0.01, 0.04) # travel time distribution while switching (multiply by 1440 minutes per day: between ~15 minutes to an hour to switch groups)
sd = 100 # sampling/observation duration in days
```

Next we make a call to `simulate_schedule()`, specifying the sampler to use. Then we'll convert the schedule object to an `igraph` graph with `graph_from_schedule()` and plot using `plot_simulated_graph()`.

```{r graph, fig.width=7, fig.height=4}
set.seed(123)
ind <- simulate_schedule(n_animals = na, 
                         n_groups = ng, 
                         time_to_leave = tl, 
                         time_to_return = tr, 
                         travel_time = tt, 
                         sampling_duration = sd,
                         simulator = "independent")

g <- graph_from_schedule(ind)
plot_simulated_graph(g, title = "independent", vertex.size = 25, mark.expand = 25)
```

## `Sample_graph()`

In `modulr` we sample networks using the `sample_graph()` function. We provide it an undirected `igraph` graph object like the one we just made, where edge weights represent the proportion of time that each pair of individuals spend together over the observation period (`sampling_duration`). We also specify the number of individuals to mark for observation using `sample_nNodes`. We wanted this function be able to handle some situations where not all individuals are observed at the same rate. Currently we can provide two observation rates, `hi_res` for "high-resolution" or more frequent observations, and `lo_res` for "low-resolution" or less frequent observations. We can adjust the proportion of sampled individuals that fall into either category using `prop_hi_res`, which is the proportion of sampled individuals that will be observed at the higher rate. (If you just want to use one observation rate, set `prop_hi_res = 1`, `hi_res` = <your rate>, and `lo_res = 0`.) We also specify a community detection algorithm (CDA) to use via `alg`. This will support CDAs from `igraph` including "fast_greedy", "walktrap", "louvain", "label_prop" and if you have the `rnetcarto` package installed, also "netcarto".

The output of sample_graph() is an `igraph` graph where the edge weights represent the simple ratio index (SRI). Here SRI is calculated based on the probability that two individuals were jointly observed given their observation frequencies. The number of joint observations for a dyad, $Y$, is taken to be a random draw from a binomial distribution governed by the proportion of time the pair spends together ($p$), and the smallest number of observations per individual of the dyad according to the user-defined sampling intensities ($n$). The SRI is then the number of joint observations divided by $n$:

$$
Y \sim Binom(n,p)
$$
$$
Pr(Y = y) = \binom{n}{y} p^y (1 - p) ^{(n - y)}
$$
$$
SRI=Y/n
$$

The package’s current implementation assumes perfect detection. As in all applications of SRI, this approach is not appropriate for dealing with the case where associations are inferred using proximity on the basis of asynchronous GPS data (“group location error”) or when individuals are routinely misidentified (Hoppitt & Farine, 2018).

### Samplers

Finally there are three 'flavors' to the sampling we can do. The first is *random* sampling and while this has useful statistical properties, it isn't always a realistic assumption -- and sometimes we knowingly violate it for good reason. Suppose we have a limited number of collars to deploy and limited resources for capturing, but we want to get at least one collar in each group so that we can monitor their movements and have a good idea of where most of the individuals are at any given time. This would be an example of our *"even"* sampler: it places one collar in each group before adding a second to any group. Once each group is represented with at least one collar it incrementally allocates remaining collars one per group. Once the smallest group is fully monitored it continues incrementally adding collars where possible. (It essentially allocates collars perfectly evenly.) The third and final 'flavor' is one we hypothesized would enhance our ability to estimate global network statistics like modularity when sample sizes are small and is also potentially more realistic to implement in practice than perfect 'evenness'. This sampled is called *"grab-two"*. In it, two individuals of a shared social group are sampled before sampling additional social groups. Once two individuals are sampled from each social group additional individuals are selected randomly. The general idea is that we want to maximize spread across social groups, but if you only sample one individual from a group you may be at a disadvantage when it comes to using community detection algorithms or estimating other global network properties.

Now let's put this into practice. We'll hold everything constant except the sampler. To help illustrate the difference between samplers we'll sample 9 animals, they'll be monitored for 100 days, and they'll have two observation frequencies. Half will be observed once per day, and the other half will be observed once per week. We'll apply the "netcarto" community detection algorithm from `rnetcarto` to make our best guess at what the social groupings should be in this sampled graph.

```{r sample-graph, fig.width=7, fig.height=2}
sn <- 9
set.seed(1234)
g_random <- sample_graph(graph = g, 
                         sample_nNodes = sn, 
                         sampling_duration = sd,
                         prop_hi_res = 0.5, 
                         hi_res = 1, 
                         lo_res = 1/7, 
                         regime = "random", 
                         alg = "netcarto")

g_even <- sample_graph(graph = g, 
                         sample_nNodes = sn, 
                         sampling_duration = sd,
                         prop_hi_res = 0.5, 
                         hi_res = 1, 
                         lo_res = 1/7, 
                         regime = "even", 
                         alg = "netcarto")

g_grab <- sample_graph(graph = g, 
                       sample_nNodes = sn, 
                       sampling_duration = sd,
                       prop_hi_res = 0.5, 
                       hi_res = 1, 
                       lo_res = 1/7, 
                       regime = "grab-two", 
                       alg = "netcarto")

par(mfrow = c(1, 3), oma = c(0, 0, 1, 0), mar = c(0, 0, 2, 0), xpd = NA)
plot_sampled_graph(g_obs = g_random, g = g, title = "Random")
plot_sampled_graph(g_obs = g_even, g = g, title = "Even")
plot_sampled_graph(g_obs = g_grab, g = g, title = "Grab-two")
```






















